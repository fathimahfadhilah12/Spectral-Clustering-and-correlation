{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhShIXcLdITr",
        "outputId": "12ca1619-3d78-492e-b448-91a1a2eade72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.48.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.0.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.48.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.48.0 watchdog-6.0.0\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.3.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.3.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.3.0\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting streamlit-option-menu\n",
            "  Downloading streamlit_option_menu-0.4.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: streamlit>=1.36 in /usr/local/lib/python3.11/dist-packages (from streamlit-option-menu) (1.48.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.36->streamlit-option-menu) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.36->streamlit-option-menu) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.36->streamlit-option-menu) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.36->streamlit-option-menu) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.36->streamlit-option-menu) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.36->streamlit-option-menu) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.36->streamlit-option-menu) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.36->streamlit-option-menu) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.36->streamlit-option-menu) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.36->streamlit-option-menu) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.36->streamlit-option-menu) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.36->streamlit-option-menu) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.36->streamlit-option-menu) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.36->streamlit-option-menu) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.36->streamlit-option-menu) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.36->streamlit-option-menu) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.36->streamlit-option-menu) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.36->streamlit-option-menu) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (2.0.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.36->streamlit-option-menu) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit>=1.36->streamlit-option-menu) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit>=1.36->streamlit-option-menu) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit>=1.36->streamlit-option-menu) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit-option-menu) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit-option-menu) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit-option-menu) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit-option-menu) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.36->streamlit-option-menu) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit>=1.36->streamlit-option-menu) (1.17.0)\n",
            "Downloading streamlit_option_menu-0.4.0-py3-none-any.whl (829 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.3/829.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: streamlit-option-menu\n",
            "Successfully installed streamlit-option-menu-0.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok\n",
        "!pip install scikit-learn openpyxl pandas\n",
        "!pip install streamlit-option-menu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eItQdOfRdQ3y",
        "outputId": "df67c9e4-31d2-491a-af7d-e57d0496477c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pydeck as pdk\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import hashlib\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics.pairwise import pairwise_kernels\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from streamlit_option_menu import option_menu\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "# Set konfigurasi halaman Streamlit\n",
        "st.set_page_config(page_title=\"Aplikasi Pengaruh Prakerja dan Klasterisasi Prakerja terhadap Tingkat Pengangguran Jawa Barat\", layout=\"wide\")\n",
        "\n",
        "# Judul aplikasi\n",
        "st.markdown(\n",
        "    \"<h1 style='text-align: center; color: navy;'>Aplikasi Pengaruh Prakerja dan Klasterisasi Prakerja terhadap Tingkat Pengangguran Jawa Barat</h1>\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "# Sidebar menu dengan option_menu\n",
        "with st.sidebar:\n",
        "    selected = option_menu(\n",
        "        menu_title=None,\n",
        "        options=[\"Upload Data\", \"Proses Analisis\",\"Analisis Klaster\", \"Rata-Rata Klaster\",\"Analisis Pengaruh Prakerja terhadap Pengangguran\",\"Input Data Manual\"],\n",
        "        icons=[\"cloud-upload\", \"gear\", \"bar-chart\", \"calculator\",\"graph-up-arrow\",\"pencil-square\"],\n",
        "        default_index=0,\n",
        "        styles={\n",
        "            \"container\": {\"padding\": \"5px\", \"background-color\": \"#f0f2f6\"},\n",
        "            \"icon\": {\"color\": \"#2c3e50\", \"font-size\": \"18px\"},\n",
        "            \"nav-link\": {\n",
        "                \"font-size\": \"16px\",\n",
        "                \"text-align\": \"left\",\n",
        "                \"margin\": \"5px\",\n",
        "                \"border-radius\": \"10px\",\n",
        "                \"padding\": \"10px 20px\",\n",
        "                \"background-color\": \"#e4e6eb\",\n",
        "            },\n",
        "            \"nav-link-selected\": {\n",
        "                \"background-color\": \"#0d6efd\",\n",
        "                \"color\": \"white\",\n",
        "                \"font-weight\": \"bold\",\n",
        "            },\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Menu Upload Data\n",
        "if selected == \"Upload Data\":\n",
        "    st.header(\"📂 Upload Data\")\n",
        "    st.info(\"Silakan upload file untuk mulai proses.\")\n",
        "\n",
        "    # Uploader untuk file CSV atau Excel\n",
        "    uploaded_file = st.file_uploader(\"Upload file data\", type=[\"xlsx\"], key=\"upload_data\")\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        try:\n",
        "            # Baca file sesuai ekstensi\n",
        "            if uploaded_file.name.endswith('.csv'):\n",
        "                df = pd.read_csv(uploaded_file, dtype=str)\n",
        "            elif uploaded_file.name.endswith('.xlsx'):\n",
        "                df = pd.read_excel(uploaded_file, engine='openpyxl', dtype=str)\n",
        "            else:\n",
        "                st.error(\"Format file tidak dikenali.\")\n",
        "                st.stop()\n",
        "            # Bersihkan nama kolom dari spasi\n",
        "            df.columns = df.columns.str.strip()\n",
        "\n",
        "            # Simpan ke session\n",
        "            st.session_state['df'] = df\n",
        "            st.session_state['uploaded_file'] = uploaded_file\n",
        "\n",
        "            st.success(\"File berhasil diupload!\")\n",
        "\n",
        "            # Input jumlah baris yang ingin ditampilkan\n",
        "            jumlah_baris = st.number_input(\n",
        "                \"Tampilkan berapa data?\",\n",
        "                min_value=1,\n",
        "                max_value=len(df),\n",
        "                value=min(100, len(df)),\n",
        "                step=1\n",
        "            )\n",
        "\n",
        "            # Tampilkan data\n",
        "            st.write(f\"Jumlah data: {len(df)} \")\n",
        "            st.dataframe(df.head(jumlah_baris))\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Gagal memproses file: {e}\")\n",
        "\n",
        "    elif 'df' in st.session_state:\n",
        "        df = st.session_state['df']\n",
        "        st.success(\"Menampilkan data dari sesi sebelumnya\")\n",
        "\n",
        "        jumlah_baris = st.number_input(\n",
        "            \"Tampilkan berapa baris?\",\n",
        "            min_value=1,\n",
        "            max_value=len(df),\n",
        "            value=min(100, len(df)),\n",
        "            step=1\n",
        "        )\n",
        "\n",
        "        st.write(f\"Jumlah data: {len(df)} baris\")\n",
        "        st.dataframe(df.head(jumlah_baris))\n",
        "\n",
        "# Menu Proses Analisis\n",
        "elif selected == \"Proses Analisis\":\n",
        "    st.title(\"🔍 Proses Analisis Data\")\n",
        "\n",
        "    if 'df' not in st.session_state:\n",
        "        st.warning(\"Silakan upload data terlebih dahulu di menu 'Upload Data'.\")\n",
        "        st.stop()\n",
        "\n",
        "    df = st.session_state['df'].copy()\n",
        "\n",
        "    # Ganti tanda '-' jadi NaN\n",
        "    df.replace(\"-\", np.nan, inplace=True)\n",
        "\n",
        "    # Hapus kolom yang terlalu banyak null\n",
        "    df.dropna(axis=1, thresh=0.1 * len(df), inplace=True)\n",
        "\n",
        "    # Imputasi kolom jika ada\n",
        "    imputer = SimpleImputer(strategy=\"mean\")\n",
        "    for col in ['SD ke bawah', 'Diploma I/II/III/Akademi/Universitas']:\n",
        "        if col in df.columns:\n",
        "            df[col] = imputer.fit_transform(df[[col]])\n",
        "\n",
        "    # Encode Wilayah\n",
        "    if \"Wilayah\" in df.columns:\n",
        "        df[\"Wilayah_Original\"] = df[\"Wilayah\"]\n",
        "        df[\"Wilayah_Encoded\"] = LabelEncoder().fit_transform(df[\"Wilayah\"])\n",
        "\n",
        "    # Konversi kolom numerik\n",
        "    numeric_columns = [\n",
        "        \"Jumlah angkatan Kerja\", \"Jumlah pengangguran terbuka\", \"TPT\", \"laki-laki\", \"perempuan\",\n",
        "        \"SD ke bawah\", \"SMP\", \"SMA\", \"SMK\", \"Diploma I/II/III/Akademi/Universitas\",\n",
        "        \"sk penetapan\", \"Aktif\", \"TPAK\", \"Tahun\"\n",
        "    ]\n",
        "    for col in numeric_columns:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].astype(str).str.replace(',', '', regex=True).replace('-', np.nan)\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # Pilih fitur untuk clustering\n",
        "    features_for_cluster = [\n",
        "        \"TPT\", \"Jumlah pengangguran terbuka\", \"Aktif\", \"TPAK\", \"Jumlah angkatan Kerja\",\n",
        "        \"laki-laki\", \"perempuan\", \"SD ke bawah\", \"SMP\", \"SMA\", \"SMK\", \"Diploma I/II/III/Akademi/Universitas\"\n",
        "    ]\n",
        "    X = df[features_for_cluster].dropna()\n",
        "\n",
        "    # Normalisasi\n",
        "    scaler = MinMaxScaler()\n",
        "    X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "    # Tampilkan tabel hasil normalisasi\n",
        "    st.subheader(\"Tabel Normalisasi (Min-Max)\")\n",
        "    df_normalized = pd.DataFrame(X_normalized, columns=features_for_cluster)\n",
        "    st.dataframe(df_normalized)\n",
        "    st.markdown(\"\"\"\n",
        "    Normalisasi digunakan untuk menyamakan skala data antar fitur agar tidak ada fitur yang mendominasi.\n",
        "    Di sini digunakan metode **Min-Max Scaling** untuk mengubah data ke rentang 0 hingga 1.\n",
        "    \"\"\")\n",
        "\n",
        "    # Affinity Matrix\n",
        "    st.subheader(\"Affinity Matrix (RBF Kernel)\")\n",
        "    gamma = 1.0\n",
        "    affinity_matrix = pairwise_kernels(X_normalized, metric='rbf', gamma=gamma)\n",
        "    df_affinity = pd.DataFrame(affinity_matrix)\n",
        "    st.dataframe(df_affinity)\n",
        "    st.markdown(\"\"\"\n",
        "    Matriks ini menunjukkan tingkat kedekatan atau kemiripan antar data berdasarkan fungsi kernel (di sini: **RBF kernel**).\n",
        "    Nilai mendekati 1 artinya dua data sangat mirip.\n",
        "    \"\"\")\n",
        "\n",
        "    # Degree Matrix\n",
        "    st.subheader(\"Degree Matrix\")\n",
        "    degree_matrix = np.diag(np.sum(affinity_matrix, axis=1))\n",
        "    df_degree = pd.DataFrame(degree_matrix)\n",
        "    st.dataframe(df_degree)\n",
        "    st.markdown(\"\"\"\n",
        "    Matriks diagonal yang menyimpan jumlah total hubungan (kedekatan) setiap data terhadap semua data lainnya.\n",
        "    Ini digunakan untuk menghitung Laplacian.\n",
        "    \"\"\")\n",
        "\n",
        "    # Laplacian Matrix\n",
        "    st.subheader(\"Laplacian Matrix\")\n",
        "    laplacian_matrix = degree_matrix - affinity_matrix\n",
        "    df_laplacian = pd.DataFrame(laplacian_matrix)\n",
        "    st.dataframe(df_laplacian)\n",
        "    st.markdown(\"\"\"\n",
        "    Laplacian Matrix diperoleh dari Degree Matrix dikurangi Affinity Matrix.\n",
        "    Matriks ini penting dalam algoritma Spectral Clustering karena digunakan untuk menemukan struktur klaster alami dalam data.\n",
        "    \"\"\")\n",
        "    # Simpan ke session\n",
        "    eigenvalues, eigenvectors = np.linalg.eigh(laplacian_matrix)\n",
        "    st.session_state['X_normalized'] = X_normalized\n",
        "    st.session_state['eigenvectors'] = eigenvectors[:, :2]\n",
        "    st.session_state['df_processed'] = df\n",
        "\n",
        "    # --- Hitung Eigenvalues & Eigenvectors ---\n",
        "    from scipy.linalg import eigh\n",
        "    from sklearn.metrics.pairwise import pairwise_kernels\n",
        "    from scipy.sparse import csgraph\n",
        "\n",
        "    # Gunakan Gaussian (RBF) kernel untuk affinity matrix\n",
        "    gamma = 1.0\n",
        "    affinity_matrix_gaussian = pairwise_kernels(X_normalized, metric='rbf', gamma=gamma)\n",
        "\n",
        "    # Laplacian normed\n",
        "    laplacian = csgraph.laplacian(affinity_matrix_gaussian, normed=True)\n",
        "\n",
        "    # Eigen decomposition\n",
        "    eigenvalues, eigenvectors = eigh(laplacian)\n",
        "\n",
        "    # Simpan ke session\n",
        "    st.session_state['X_normalized'] = X_normalized\n",
        "    st.session_state['eigenvectors'] = eigenvectors[:, 1:3]  # ambil eigenvector ke-2 dan ke-3\n",
        "    st.session_state['df_processed'] = df\n",
        "\n",
        "    # --- Tampilkan Eigenvectors ---\n",
        "    st.subheader(\"Eigenvectors (2D Embedding)\")\n",
        "    df_eigenvectors = pd.DataFrame(eigenvectors[:, 1:3], columns=[\"Eigenvector 2\", \"Eigenvector 3\"])\n",
        "    st.dataframe(df_eigenvectors)\n",
        "    st.markdown(\"\"\"\n",
        "    Eigenvectors digunakan untuk memproyeksikan data ke ruang berdimensi lebih rendah\n",
        "    sehingga memudahkan proses clustering.\n",
        "    Pada Spectral Clustering, biasanya diambil beberapa eigenvector dengan eigenvalue terkecil.\n",
        "    \"\"\")\n",
        "\n",
        "# Menu Analisis\n",
        "elif selected == \"Analisis Klaster\":\n",
        "    # Pastikan data sudah diupload\n",
        "    if 'df' not in st.session_state:\n",
        "        if 'uploaded_file' in st.session_state:\n",
        "            uploaded_file = st.session_state['uploaded_file']\n",
        "            if uploaded_file.name.endswith('.csv'):\n",
        "                df = pd.read_csv(uploaded_file, dtype=str)\n",
        "            else:\n",
        "                df = pd.read_excel(uploaded_file, engine='openpyxl', dtype=str)\n",
        "            st.session_state['df'] = df\n",
        "        else:\n",
        "            st.warning(\"Data belum diupload. Silakan upload data dulu di menu 'Upload Data'.\")\n",
        "            st.stop()\n",
        "\n",
        "    df = st.session_state['df']\n",
        "\n",
        "    # Bersihkan dan persiapkan data\n",
        "    df.columns = df.columns.str.strip()\n",
        "    df.replace(\"-\", np.nan, inplace=True)\n",
        "    df.dropna(axis=1, thresh=0.1 * len(df), inplace=True)\n",
        "\n",
        "    imputer = SimpleImputer(strategy=\"mean\")\n",
        "    for col in ['SD ke bawah', 'Diploma I/II/III/Akademi/Universitas']:\n",
        "        if col in df.columns:\n",
        "            df[col] = imputer.fit_transform(df[[col]])\n",
        "\n",
        "    if \"Wilayah\" in df.columns:\n",
        "        df[\"Wilayah_Original\"] = df[\"Wilayah\"]\n",
        "        df[\"Wilayah_Encoded\"] = LabelEncoder().fit_transform(df[\"Wilayah\"])\n",
        "\n",
        "    # Konversi kolom numerik\n",
        "    numeric_columns = [\n",
        "        \"Jumlah angkatan Kerja\", \"Jumlah pengangguran terbuka\", \"TPT\", \"laki-laki\", \"perempuan\",\n",
        "        \"SD ke bawah\", \"SMP\", \"SMA\", \"SMK\", \"Diploma I/II/III/Akademi/Universitas\", \"sk penetapan\", \"Aktif\"\n",
        "    ]\n",
        "    for col in numeric_columns:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].astype(str).str.replace(',', '', regex=True).replace('-', np.nan).astype(float)\n",
        "\n",
        "    for col in ['Tahun', 'TPAK', 'TPT']:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # Pilih fitur untuk clustering\n",
        "    features_for_cluster = [\n",
        "        \"TPT\", \"Jumlah pengangguran terbuka\", \"Aktif\", \"TPAK\", \"Jumlah angkatan Kerja\",\n",
        "        \"laki-laki\", \"perempuan\", \"SD ke bawah\", \"SMP\", \"SMA\", \"SMK\", \"Diploma I/II/III/Akademi/Universitas\"\n",
        "    ]\n",
        "    X = df[features_for_cluster].dropna()\n",
        "\n",
        "    # Normalisasi data\n",
        "    scaler = MinMaxScaler()\n",
        "    X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "    # Membuat affinity matrix dengan kernel RBF\n",
        "    gamma = 1.0\n",
        "    affinity_matrix = pairwise_kernels(X_normalized, metric='rbf', gamma=gamma)\n",
        "\n",
        "    # Hitung Laplacian matrix\n",
        "    degree_matrix = np.diag(np.sum(affinity_matrix, axis=1))\n",
        "    laplacian_matrix = degree_matrix - affinity_matrix\n",
        "\n",
        "    # Eigen decomposition\n",
        "    eigenvalues, eigenvectors = np.linalg.eigh(laplacian_matrix)\n",
        "\n",
        "    # Ambil k eigenvector pertama\n",
        "    k = 2\n",
        "    eigenvector_subset = eigenvectors[:, :k]\n",
        "\n",
        "    # Clustering spektral\n",
        "    spectral = SpectralClustering(n_clusters=2, affinity='nearest_neighbors', random_state=42)\n",
        "    cluster_labels = spectral.fit_predict(eigenvector_subset)\n",
        "\n",
        "    # Simpan hasil cluster ke dataframe\n",
        "    df.loc[X.index, 'Cluster'] = cluster_labels\n",
        "\n",
        "    # Tetapkan cluster dominan per wilayah\n",
        "    df['Cluster'] = df.groupby('Wilayah')['Cluster'].transform(lambda x: x.mode()[0])\n",
        "\n",
        "    # Konversi ulang kolom numerik\n",
        "    kolom_numerik = [\n",
        "        'TPT', 'Jumlah pengangguran terbuka', 'Aktif', 'TPAK', 'Jumlah angkatan Kerja',\n",
        "        'laki-laki', 'perempuan', 'SD ke bawah', 'SMP', 'SMA', 'SMK',\n",
        "        'Diploma I/II/III/Akademi/Universitas'\n",
        "    ]\n",
        "    for kolom in kolom_numerik:\n",
        "        df[kolom] = pd.to_numeric(df[kolom], errors='coerce')\n",
        "\n",
        "    # Hitung rata-rata per klaster dan wilayah, simpan ke CSV\n",
        "    average_cluster_data = df.groupby(['Wilayah', 'Cluster'])[kolom_numerik].mean().reset_index()\n",
        "    average_cluster_data.to_csv('Rata-rata prakerja & Pengangguran perwilayah_klaster.csv', index=False)\n",
        "\n",
        "    # Gabungkan koordinat wilayah dari file CSV eksternal\n",
        "    coords = pd.read_csv(\"koordinat_wilayah.csv\")\n",
        "    df = df.merge(coords, on=\"Wilayah\", how=\"left\")\n",
        "\n",
        "    # Bersihkan kolom yang tidak perlu\n",
        "    kolom_drop = ['Wilayah_Original', 'Wilayah_Encoded', 'No', 'No.']\n",
        "    df = df.drop(columns=[k for k in kolom_drop if k in df.columns])\n",
        "\n",
        "    # Susun ulang kolom agar lebih terstruktur\n",
        "    kolom_utama = ['Tahun', 'Wilayah', 'Cluster']\n",
        "    kolom_lain = [col for col in df.columns if col not in kolom_utama]\n",
        "    df = df[kolom_utama + kolom_lain]\n",
        "\n",
        "    # Tampilkan data lengkap\n",
        "    st.subheader(\"📋 Data Klasterisasi Lengkap\")\n",
        "    st.dataframe(df)\n",
        "\n",
        "    # Form filter untuk tahun dan cluster\n",
        "    with st.form(\"filter_form\"):\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            tahun_terpilih = st.selectbox(\"📅 Pilih Tahun\", sorted(df['Tahun'].dropna().unique()))\n",
        "        with col2:\n",
        "            klaster_terpilih = st.multiselect(\"🔢 Pilih Klaster\", sorted(df['Cluster'].dropna().unique()), default=sorted(df['Cluster'].dropna().unique()))\n",
        "        filter_submit = st.form_submit_button(\"🔍 Terapkan Filter\")\n",
        "\n",
        "    if filter_submit:\n",
        "        df_tahun = df[df['Tahun'] == tahun_terpilih]\n",
        "        df_klaster = df_tahun[df_tahun['Cluster'].isin(klaster_terpilih)]\n",
        "\n",
        "        st.subheader(\"📄 Data Klaster Terfilter\")\n",
        "        st.dataframe(df_klaster)\n",
        "\n",
        "        st.markdown(\"\"\"\n",
        "               ### Hasil Klaster:\n",
        "               Data wilayah dikelompokkan menjadi **2 klaster utama**:\n",
        "\n",
        "               - **Cluster 0**:\n",
        "                     - Cenderung memiliki TPT dan jumlah pengangguran yang lebih tinggi.\n",
        "                     - Partisipasi Prakerja lebih besar → menunjukkan upaya intervensi terhadap pengangguran cukup aktif.\n",
        "                     - Komposisi angkatan kerja lebih besar pada jenjang pendidikan menengah (SMA/SMK).\n",
        "\n",
        "              - **Cluster 1**:\n",
        "                    - Memiliki TPT yang lebih rendah dan jumlah pengangguran terbuka lebih sedikit**.\n",
        "                    - Jumlah peserta aktif Prakerja relatif rendah, karena wilayah ini cenderung lebih stabil dari segi ketenagakerjaan.\n",
        "                    - TPK lebih baik dan distribusi pendidikan cenderung lebih merata.\n",
        "\n",
        "            \"\"\")\n",
        "        # Konversi Cluster ke string agar cocok dengan color_discrete_map\n",
        "        df_klaster = df_klaster.copy()\n",
        "        df_klaster['Cluster'] = df_klaster['Cluster'].astype(int).astype(str)\n",
        "\n",
        "\n",
        "        # Buat dictionary warna khusus\n",
        "        # Mapping warna manual\n",
        "        df_klaster['warna'] = df_klaster['Cluster'].map({\n",
        "            '0': 'yellow',\n",
        "            '1': 'blue'\n",
        "        })\n",
        "        # Plot manual pakai graph_objects\n",
        "        fig = go.Figure()\n",
        "        # Loop per klaster → satu trace saja per klaster\n",
        "        for cluster_label in df_klaster['Cluster'].unique():\n",
        "            df_sub = df_klaster[df_klaster['Cluster'] == cluster_label]\n",
        "            fig.add_trace(go.Scattermapbox(\n",
        "                lat=df_sub['lat'],\n",
        "                lon=df_sub['lon'],\n",
        "                mode='markers',\n",
        "                marker=go.scattermapbox.Marker(\n",
        "                    size=12,\n",
        "                    color=df_sub['warna'].iloc[0]  # ambil warna konsisten\n",
        "                ),\n",
        "                name=f\"Cluster {cluster_label}\",\n",
        "                text=df_sub.apply(lambda row: f\"Wilayah: {row['Wilayah']}<br>Cluster: {row['Cluster']}\", axis=1),\n",
        "                hoverinfo='text'\n",
        "        ))\n",
        "        fig.update_layout(\n",
        "            mapbox=dict(\n",
        "                style=\"open-street-map\",\n",
        "                center=dict(lat=-7.0, lon=107.5),\n",
        "                zoom=6\n",
        "            ),\n",
        "            showlegend=True,\n",
        "            height=500\n",
        "        )\n",
        "        st.subheader(\"🗺️ Visualisasi Peta Klasterisasi Wilayah\")\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "    else:\n",
        "      st.warning(\"\")\n",
        "\n",
        "# Menu Rata-Rata\n",
        "elif selected == \"Rata-Rata Klaster\":\n",
        "    if 'df' not in st.session_state:\n",
        "        st.warning(\"Data belum tersedia. Silakan lakukan upload dan analisis data terlebih dahulu.\")\n",
        "        st.stop()\n",
        "\n",
        "    df = st.session_state['df']\n",
        "\n",
        "    # Gunakan modus klaster per wilayah (klaster paling sering muncul)\n",
        "    df['Cluster'] = df.groupby('Wilayah')['Cluster'].transform(lambda x: x.mode()[0])\n",
        "\n",
        "    # Konversi kolom numerik ke tipe numerik\n",
        "    kolom_numerik = [\n",
        "        'TPT', 'Jumlah pengangguran terbuka', 'Aktif', 'TPAK', 'Jumlah angkatan Kerja',\n",
        "        'laki-laki', 'perempuan', 'SD ke bawah', 'SMP', 'SMA', 'SMK',\n",
        "        'Diploma I/II/III/Akademi/Universitas'\n",
        "    ]\n",
        "    for kolom in kolom_numerik:\n",
        "        df[kolom] = pd.to_numeric(df[kolom], errors='coerce')\n",
        "\n",
        "    # Hitung rata-rata indikator per wilayah dan klaster\n",
        "    average_cluster_data = df.groupby(['Wilayah', 'Cluster'])[kolom_numerik].mean().reset_index()\n",
        "    average_cluster_data.to_csv('Rata-rata prakerja & Pengangguran perwilayah_klaster.csv', index=False)\n",
        "\n",
        "    # Hitung rata-rata per klaster (tanpa membedakan wilayah)\n",
        "    rata_rata_klaster = df.groupby('Cluster')[kolom_numerik].mean().reset_index()\n",
        "\n",
        "    # Tampilkan tabel hasil\n",
        "    st.subheader(\"📊 Rata-rata Indikator per Tahun, Wilayah, dan Klaster\")\n",
        "    st.dataframe(average_cluster_data)\n",
        "\n",
        "    st.subheader(\"📊 Rata-rata Indikator per Klaster\")\n",
        "    st.dataframe(rata_rata_klaster)\n",
        "\n",
        "    # Penjelasan klaster 0\n",
        "    st.markdown(\"\"\"\n",
        "        ### 🟡 Cluster 0 — Wilayah dengan Populasi Kerja Besar dan Pengangguran Tinggi\n",
        "\n",
        "        - **TPT**: `8.95%`\n",
        "        - **Jumlah Pengangguran Terbuka**: `137.209 orang`\n",
        "        - **Peserta Aktif**: `37.581 orang`\n",
        "        - **TPAK**: `65.77%`\n",
        "        - **Jumlah Angkatan Kerja**: `1.513.606 orang`\n",
        "\n",
        "        **Komposisi Pendidikan Pengangguran:**\n",
        "        - SD ke bawah: `29.165`\n",
        "        - SMP: `26.386`\n",
        "        - SMA: `33.946`\n",
        "        - SMK: `35.560`\n",
        "        - Diploma/Universitas: `18.866`\n",
        "\n",
        "        **Karakteristik:**\n",
        "        Wilayah dengan jumlah pengangguran tinggi, didominasi oleh lulusan SMK dan SMA.\n",
        "        Kemungkinan besar merupakan wilayah perkotaan dengan tingkat kompetisi kerja tinggi.\n",
        "    \"\"\")\n",
        "\n",
        "    # Penjelasan klaster 1\n",
        "    st.markdown(\"\"\"\n",
        "        ### 🔵 Cluster 1 — Wilayah dengan Skala Kecil dan Pengangguran Lebih Rendah\n",
        "\n",
        "        - **TPT**: `7.65%`\n",
        "        - **Jumlah Pengangguran Terbuka**: `41.636 orang`\n",
        "        - **Peserta Aktif**: `12.236 orang`\n",
        "        - **TPAK**: `66.63%`\n",
        "        - **Jumlah Angkatan Kerja**: `558.028 orang`\n",
        "\n",
        "        **Komposisi Pendidikan Pengangguran:**\n",
        "        - SD ke bawah: `16.158`\n",
        "        - SMP: `13.880`\n",
        "        - SMA: `12.981`\n",
        "        - SMK: `13.955`\n",
        "        - Diploma/Universitas: `12.589`\n",
        "\n",
        "        **Karakteristik:**\n",
        "        Wilayah dengan jumlah tenaga kerja dan penganggur yang lebih kecil.\n",
        "        Umumnya merupakan wilayah rural atau kota kecil dengan tekanan kerja lebih rendah.\n",
        "    \"\"\")\n",
        "\n",
        "    # ======= VISUALISASI PETA RATA-RATA PER KLASTER =======\n",
        "\n",
        "    try:\n",
        "        coords = pd.read_csv(\"koordinat_wilayah.csv\")\n",
        "\n",
        "        # Gabungkan koordinat dengan data rata-rata\n",
        "        average_cluster_map = average_cluster_data.merge(coords, on='Wilayah', how='left')\n",
        "        average_cluster_map = average_cluster_map.dropna(subset=['lat', 'lon'])\n",
        "\n",
        "        # Konversi cluster ke string & buat kolom warna\n",
        "        average_cluster_map['Cluster'] = average_cluster_map['Cluster'].astype(int).astype(str)\n",
        "        average_cluster_map['warna'] = average_cluster_map['Cluster'].map({\n",
        "            '0': 'yellow',\n",
        "            '1': 'blue'\n",
        "        })\n",
        "\n",
        "        # Buat peta\n",
        "        fig = go.Figure()\n",
        "\n",
        "        for cluster_label in average_cluster_map['Cluster'].unique():\n",
        "            df_sub = average_cluster_map[average_cluster_map['Cluster'] == cluster_label]\n",
        "\n",
        "            if not df_sub.empty and pd.notna(df_sub['warna'].iloc[0]):\n",
        "                fig.add_trace(go.Scattermapbox(\n",
        "                    lat=df_sub['lat'],\n",
        "                    lon=df_sub['lon'],\n",
        "                    mode='markers',\n",
        "                    marker=go.scattermapbox.Marker(\n",
        "                        size=14,\n",
        "                        color=df_sub['warna'].iloc[0]\n",
        "                    ),\n",
        "                    name=f\"Cluster {cluster_label}\",\n",
        "                    text=df_sub.apply(lambda row: f\"Wilayah: {row['Wilayah']}<br>Cluster: {row['Cluster']}\", axis=1),\n",
        "                    hoverinfo='text'\n",
        "                ))\n",
        "\n",
        "        # Layout peta\n",
        "        fig.update_layout(\n",
        "            mapbox=dict(\n",
        "                style=\"open-street-map\",\n",
        "                center=dict(\n",
        "                    lat=average_cluster_map['lat'].mean(),\n",
        "                    lon=average_cluster_map['lon'].mean()\n",
        "                ),\n",
        "                zoom=6\n",
        "            ),\n",
        "            showlegend=True,\n",
        "            height=500\n",
        "        )\n",
        "\n",
        "        st.subheader(\"🗺️ Peta Rata-rata Indikator per Klaster\")\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        st.warning(f\"❗Tidak ada data koordinat rata-rata indikator yang tersedia untuk divisualisasikan.\\n\\nDetail: {e}\")\n",
        "\n",
        "# Menu Analisis Pengaruh Prakerja terhadap Pengangguran\n",
        "elif selected == \"Analisis Pengaruh Prakerja terhadap Pengangguran\":\n",
        "    if 'df' not in st.session_state:\n",
        "        st.warning(\"Data belum diupload. Silakan upload data terlebih dahulu.\")\n",
        "        st.stop()\n",
        "\n",
        "    df = st.session_state['df']\n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    # --- Bagian 1: Korelasi Prakerja dengan Pengangguran dan Pendidikan ---\n",
        "    st.header(\"Korelasi Prakerja terhadap Pengangguran dan Pendidikan\")\n",
        "\n",
        "    kolom_utama = ['Aktif', 'TPT']\n",
        "    kolom_pendidikan = ['Aktif', 'SD ke bawah', 'SMP', 'SMA', 'SMK', 'Diploma I/II/III/Akademi/Universitas']\n",
        "\n",
        "    if not all(kol in df.columns for kol in kolom_utama):\n",
        "        st.error(\"Kolom 'Aktif' dan/atau 'TPT' tidak tersedia di dataset.\")\n",
        "    elif not all(kol in df.columns for kol in kolom_pendidikan):\n",
        "        st.error(\"Beberapa kolom pendidikan tidak tersedia di dataset.\")\n",
        "    else:\n",
        "        # Korelasi Aktif dan TPT\n",
        "        korelasi_aktif_tpt = df[kolom_utama].corr()\n",
        "        st.subheader(\"📌 Korelasi antara 'Aktif' dan 'TPT'\")\n",
        "        st.dataframe(korelasi_aktif_tpt)\n",
        "        st.markdown(\"\"\"\n",
        "        **Interpretasi Hasil Korelasi (Aktif dan TPT)**\n",
        "\n",
        "        - **Nilai korelasi:** 0,35 (hubungan sedang dan positif)\n",
        "        - **Makna:** Partisipasi aktif dalam Program Kartu Prakerja berkaitan dengan tingkat pengangguran, namun tidak kuat.\n",
        "        - **Kesimpulan:**\n",
        "        - Program Prakerja belum berpengaruh signifikan terhadap penurunan pengangguran.\n",
        "        - Faktor lain seperti pasar kerja dan keterampilan tetap berperan penting.\n",
        "        \"\"\")\n",
        "\n",
        "        # Korelasi Aktif dan Pendidikan\n",
        "        korelasi_aktif_pendidikan = df[kolom_pendidikan].corr()\n",
        "        st.subheader(\"📌 Korelasi antara 'Aktif' dan Jenjang Pendidikan\")\n",
        "        st.dataframe(korelasi_aktif_pendidikan)\n",
        "        st.markdown(\"\"\"\n",
        "        **Penjelasan**\n",
        "\n",
        "        - **Peserta Prakerja (Aktif)** paling banyak berasal dari lulusan **SMA (korelasi 0.64)** dan **SMK (0.63)**.\n",
        "        - Peserta dari lulusan **SD ke bawah (0.41)** dan **SMP (0.39)** ada juga, tapi jumlahnya lebih sedikit.\n",
        "        - Peserta dari lulusan **Diploma/Universitas (0.05)** sangat sedikit atau hampir tidak ada.\n",
        "\n",
        "        **Kesimpulan:** Program Prakerja lebih diminati oleh lulusan SMA dan SMK, sementara lulusan perguruan tinggi relatif sedikit yang ikut.\n",
        "        \"\"\")\n",
        "    st.header(\"Pengaruh program Kartu Prakerja\")\n",
        "    required_cols = {'Tahun', 'Aktif', 'TPT'}\n",
        "    if not required_cols.issubset(df.columns):\n",
        "        st.error(\"Data harus memiliki kolom 'Tahun', 'Aktif', dan 'TPT'.\")\n",
        "        st.stop()\n",
        "\n",
        "    # Bagi berdasarkan partisipasi tinggi vs rendah\n",
        "    high_participation = df[df['Aktif'] > df['Aktif'].median()]\n",
        "    low_participation = df[df['Aktif'] <= df['Aktif'].median()]\n",
        "\n",
        "    # Tahun awal program Prakerja (2020)\n",
        "    high_participation_2020 = high_participation[high_participation['Tahun'] == 2020]['TPT']\n",
        "    high_participation_after = high_participation[high_participation['Tahun'] >= 2021]['TPT']\n",
        "\n",
        "    low_participation_2020 = low_participation[low_participation['Tahun'] == 2020]['TPT']\n",
        "    low_participation_after = low_participation[low_participation['Tahun'] >= 2021]['TPT']\n",
        "\n",
        "    # Hitung rata-rata TPT\n",
        "    avg_tpt_high_2020 = high_participation_2020.mean()\n",
        "    avg_tpt_high_after = high_participation_after.mean()\n",
        "\n",
        "    avg_tpt_low_2020 = low_participation_2020.mean()\n",
        "    avg_tpt_low_after = low_participation_after.mean()\n",
        "\n",
        "    # Tampilkan hasil\n",
        "    st.markdown(f\"**Wilayah dengan partisipasi tinggi Prakerja:**\")\n",
        "    st.markdown(f\"- TPT tahun 2020 (awal program): **{avg_tpt_high_2020:.2f}%**\")\n",
        "    st.markdown(f\"- TPT tahun 2021–2024: **{avg_tpt_high_after:.2f}%**\")\n",
        "\n",
        "    st.markdown(f\"**Wilayah dengan partisipasi rendah Prakerja:**\")\n",
        "    st.markdown(f\"- TPT tahun 2020 (awal program): **{avg_tpt_low_2020:.2f}%**\")\n",
        "    st.markdown(f\"- TPT tahun 2021–2024: **{avg_tpt_low_after:.2f}%**\")\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    - TPT menurun di wilayah dengan **partisipasi tinggi** maupun **rendah** dalam program Prakerja.\n",
        "    - Penurunan lebih besar terjadi di wilayah dengan **partisipasi tinggi**.\n",
        "    - Namun, karena penurunan juga terjadi di wilayah partisipasi rendah, **Prakerja bukan satu-satunya faktor**.\n",
        "    - Faktor lain seperti **kondisi ekonomi dan kebijakan pemerintah** juga berperan.\n",
        "    \"\"\")\n",
        "\n",
        "    # Visualisasi perbandingan\n",
        "    st.subheader(\"📈 Visualisasi Perbandingan\")\n",
        "\n",
        "    chart_data = pd.DataFrame({\n",
        "        'Kategori': ['Tinggi 2020', 'Tinggi 2021–2024', 'Rendah 2020', 'Rendah 2021–2024'],\n",
        "        'TPT': [avg_tpt_high_2020, avg_tpt_high_after, avg_tpt_low_2020, avg_tpt_low_after]\n",
        "    })\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.bar(chart_data['Kategori'], chart_data['TPT'], color=['blue', 'blue', 'orange', 'orange'])\n",
        "    ax.set_ylabel(\"Tingkat Pengangguran Terbuka (%)\")\n",
        "    ax.set_title(\"Perbandingan Rata-rata TPT Berdasarkan Partisipasi Prakerja\")\n",
        "    st.pyplot(fig)\n",
        "\n",
        "# Menu Input Data Manual\n",
        "elif selected == \"Input Data Manual\":\n",
        "\n",
        "    # Menu Input Data Manual\n",
        "    st.header(\"📝 Input Data Manual untuk Cluster\")\n",
        "\n",
        "    if 'df' not in st.session_state:\n",
        "        st.warning(\"Data belum diupload. Silakan upload data dulu di menu Upload Data.\")\n",
        "    else:\n",
        "        df = st.session_state['df']\n",
        "\n",
        "        features_for_cluster = [\n",
        "            \"TPT\", \"Jumlah pengangguran terbuka\", \"Aktif\", \"TPAK\", \"Jumlah angkatan Kerja\",\n",
        "            \"laki-laki\", \"perempuan\", \"SD ke bawah\", \"SMP\", \"SMA\", \"SMK\", \"Diploma I/II/III/Akademi/Universitas\"\n",
        "        ]\n",
        "\n",
        "        missing_cols = [col for col in features_for_cluster if col not in df.columns]\n",
        "        if missing_cols:\n",
        "            st.error(f\"Kolom berikut tidak ditemukan dalam data: {missing_cols}\")\n",
        "            st.write(\"Kolom-kolom yang ada di data:\")\n",
        "            st.write(df.columns.tolist())\n",
        "            st.stop()\n",
        "\n",
        "        X = df[features_for_cluster].astype(float)\n",
        "        scaler = StandardScaler()\n",
        "        X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "        gamma = 0.1\n",
        "        k = 2\n",
        "\n",
        "        if 'Wilayah' in df.columns:\n",
        "            wilayah_list = df['Wilayah'].dropna().unique().tolist()\n",
        "            if not wilayah_list:\n",
        "                wilayah_list = [\"N/A\"]\n",
        "        else:\n",
        "            wilayah_list = [\"N/A\"]\n",
        "\n",
        "        with st.form(\"form_input_manual\"):\n",
        "            input_data = {}\n",
        "            cols = st.columns(3)\n",
        "\n",
        "            for i, feature in enumerate(features_for_cluster):\n",
        "                with cols[i % 3]:\n",
        "                    input_data[feature] = st.number_input(f\"{feature}\", value=0.0, step=1.0)\n",
        "\n",
        "            input_tahun = st.number_input(\"Tahun\", min_value=2000, max_value=2100, value=2023, step=1)\n",
        "            input_wilayah = st.selectbox(\"Wilayah\", options=wilayah_list)\n",
        "\n",
        "            submitted = st.form_submit_button(\"🔍 Klaster\")\n",
        "\n",
        "        if submitted:\n",
        "            try:\n",
        "                input_df = pd.DataFrame([input_data])\n",
        "\n",
        "                # Validasi apakah ada NaN\n",
        "                if input_df.isnull().values.any():\n",
        "                    st.error(\"❌ Input Anda mengandung nilai kosong (NaN). Harap isi semua kolom dengan benar.\")\n",
        "                    st.stop()\n",
        "\n",
        "                input_normalized = scaler.transform(input_df)\n",
        "                combined_normalized = np.vstack([X_normalized, input_normalized])\n",
        "\n",
        "                combined_affinity = pairwise_kernels(combined_normalized, metric='rbf', gamma=gamma)\n",
        "                combined_degree = np.diag(np.sum(combined_affinity, axis=1))\n",
        "                combined_laplacian = combined_degree - combined_affinity\n",
        "\n",
        "                _, combined_eigenvectors = np.linalg.eigh(combined_laplacian)\n",
        "                combined_subset = combined_eigenvectors[:, :k]\n",
        "\n",
        "                spectral = SpectralClustering(n_clusters=k, affinity='nearest_neighbors', random_state=42)\n",
        "                combined_labels = spectral.fit_predict(combined_subset)\n",
        "\n",
        "                predicted_cluster = combined_labels[-1]\n",
        "\n",
        "                st.success(f\"✅ Data yang Anda input masuk ke **Cluster {predicted_cluster}**.\")\n",
        "                st.markdown(\"**Detail Data yang Dimasukkan:**\")\n",
        "                st.write(input_df)\n",
        "                st.markdown(f\"📅 Tahun: **{input_tahun}**  | 🌍 Wilayah: **{input_wilayah}**\")\n",
        "\n",
        "                # 🔍 Korelasi Antar Fitur\n",
        "                st.subheader(\"🔍 Korelasi Antar Fitur\")\n",
        "                selected_features = [\n",
        "                    'Aktif', 'TPT',\n",
        "                    'SD ke bawah', 'SMP', 'SMA', 'SMK',\n",
        "                    'Diploma I/II/III/Akademi/Universitas'\n",
        "                ]\n",
        "\n",
        "                 # Cek apakah semua input bernilai nol\n",
        "                if all(value == 0.0 for value in input_data.values()):\n",
        "                    st.warning(\"📭 Anda belum mengisi data apapun. Korelasi tidak dapat dihitung dari input kosong.\")\n",
        "                else:\n",
        "                    # Simulasikan 10 baris dari input user dengan variasi kecil\n",
        "                    simulated_inputs = pd.DataFrame([input_data] * 10)\n",
        "                    seed_value = int(hashlib.md5(str(input_data).encode()).hexdigest(), 16) % (2**32)\n",
        "                    np.random.seed(seed_value)\n",
        "                    noise = np.random.normal(0, 0.01, simulated_inputs[selected_features].shape)\n",
        "                    simulated_inputs[selected_features] += noise\n",
        "\n",
        "                    corr_matrix = simulated_inputs[selected_features].corr()\n",
        "                    st.dataframe(\n",
        "                        corr_matrix.style.background_gradient(cmap='coolwarm').format(\"{:.3f}\")\n",
        "                    )\n",
        "\n",
        "                    st.markdown(\"\"\"\n",
        "                    Penjelasan Korelasi:\n",
        "                    - Nilai **mendekati 1** atau **-1** artinya hubungan **kuat**.\n",
        "                    - Nilai **mendekati 0** artinya hubungan **lemah**\n",
        "\n",
        "                    \"\"\")\n",
        "\n",
        "            except Exception as e:\n",
        "                st.error(f\"❌ Terjadi error saat memproses data: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reAW0pOneaGE",
        "outputId": "17f2288c-6ddb-48ba-c1ec-deb8684b3d30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok config add-authtoken 2w7tzu4F7z7FY97gMXIlVIrPywM_4ofdSWDtbLssEUtPVJ5pc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS_iZNFEesM7",
        "outputId": "7635b717-4c12-4314-f265-03dedf81dea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "URL publiknya: NgrokTunnel: \"https://d906d2c8a79a.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.229.37.9:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Buka port 8501 untuk Streamlit\n",
        "public_url = ngrok.connect(8501)  # Tanpa 'port='\n",
        "print(\"URL publiknya:\", public_url)\n",
        "\n",
        "\n",
        "# Jalanin Streamlit\n",
        "!streamlit run app.py &\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}